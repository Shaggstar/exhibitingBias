
Morality lets humans scale. It broadens our social roles and minds. We can sit beside strangers in airplanes and read books by people we will never meet. Morality is critical in expanding our identity to include anonymous people, curbing the potential conflicts between the roles we carry, and cueing shared expectations for behavior and interpretation. It forms the origins and foundation of what makes us distinctly human, i.e. how we use symbols to construct models that represent any material phenomenon we observe or fantasy we may conjure. 

As overwhelming of an impact AI has made on society, its most impressive capabilities lie in the future.  Should we really race towards generally intelligent systems (AGI) that may dwarf our own?  What constraints can we reasonably impose on such hyper capable robots? I argue that the only way to ensure that our creations align to our values is to better understand morality, as an innate and formal tools.  This is necessary not only necessary for alignment, but it's fundamental to the nature of our symbolic cognition and general intelligence. 

Our first and most foundational form of symbolic thinking is moral, we instinctively organize social behavior to moral codes, organizing a central evolutionary and developmental pillar, the boundaries of identity. Our ability to inhabit societies with anonymous agents and practice cultural learning and evolution could not exist without stable expectations of behavior, a practice we clearly exhibit with signs of innate morality. 

Given that humans are the most prominent example of a generally intelligent agent, computationally  representing how humanity has achieved it in a moral context may offer native governance, i.e. a way for synthetic agents to align to our interests because they grow inside our moral frame. This could apply to agents themselves and enable third party governance systems that polices other AI systems. 

While in some sense this is a new problem; in another it is the oldest human drama, learning how we each live among strangers who are nonetheless generally intelligent.

Across development and history, moral intuitions arrive early, stir the emotions that drive social life, and nudge us to rationalize our feelings in ways both ancient and oddly new. They steady expectations when incentives alone would fracture the comfort of prediction. Symbols begin with social valuation. That was our doorway into what the ancient Greeks called the logos, our ability and impulse to place ourselves in a complex hierarchy that extends beyond the signals of our senses. To imagine a shared identity, a cultural and ultimately a divine perspective. 