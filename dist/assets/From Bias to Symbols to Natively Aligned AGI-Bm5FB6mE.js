const e=`---
title: From Bias to Symbols to Natively Aligned AGI
kind: Final
tags:
  - essay
date: 2025-08-29
summary:
URL:
subtitle: https://shaggy.substack.com/p/the-myth-that-matters-from-cognitive
---

From 2020 to now, as the world went from isolated lockdown to collectively confronting the super-hype AI cycle, I've watched two young girls develop their own general intelligence capacities. They each curated their own datasets and went about labeling and modeling causal factors without, to the best of my knowledge, the assistance of any canny statistical programmers. 

Most impressively, no one needed to funnel the energy output of a dozen formerly foreclosed nuclear power plants to generate this intelligence. They acquired the vast majority of this data freely in multimodal settings, which contrasts with our world burning through electricity as we build ChatGPT's model 6.1 chasing an LLM driven AGI system. 

Every morning my daughters examine the world through the prism of intention and identification. They have "their" things and recognize other people's. Though their vision of the world largely exists between home, daycare, and my parents near Boston, they take possessin of as many parts and people of the world as possible. Importantly, although it is suspiciously motivated by their own perception of self-victimhood, they have an natural impulse for moral treatment that keeps the increasingly expansive world they inhabit together. Sissy should not be allowed to spend more time with a toy than herself. 

For a time, when I told my 1.5-year-old to say "thank you," she responded with a guttural roar not unlike that of her Grandma's canine of the same age. Yet now, she says (screams) "thank you." She accepts that arbitrary sounds have meaning.  Mean embued not just bybeyond what random people ascribe to them.

Humanity possess a unique capacity to shape the world, one that begins with our perception. Language and our symbolic capacity more generally is the ability to construct and share models of the world, it is the ability to bring the world in line with our creative constructions. This cognitive strength does not lie in so much in the *discovery* of objectivity, but rather in our simultaneous impulse to find it and inability to achieve it. We are constantly shaping the sounds and spellings of words in language, working thorugh mathematical proofs and scientific theoreoms, and shifting etchings in our art. 

Those arbitrary sounds that blend to "thank you" have meaning beyond what even the greatest Daddy on the planet says they do. They inhabit not just a shared perspective, but a singular perspective that governs and thereby subordinates the otherwise varied and innumerable perspectives that make up cultures and societies.

The biases we're taught to overcome are actually the engine of culture, morality, and ultimately, the very mechanisms we need to ensure AI systems serve human flourishing rather than exploit it.

The central claim of the **Myth of Objectivity Hypothesis** is that human intelligence is built on a myth, a belief in a specific type of universality. The shared belief that we can access some common, objective reality is not a flaw to correct, but our most powerful technology for scaling cooperation and meaning-making. Crucially, it's the pathway toward building AI systems that genuinely align with human values.

## The Architecture of Alignment

Artificial intelligence advances through structures that autonomously solve individual problems while integrating into wider connected webs of capability. This follows the same fundamental pattern we see in human consciousness and culture, though apparently with significantly higher energy requirements.

You, (excluding extant or future robots reading this and NOT built aligning with MOH computational design principles), don't exist as an isolated decision-maker. Instead, you contextualize your goals as part of broader purposes. You serve your family, contributing to your profession, participating in communities that stretch beyond any specific named group. You find meaning by harmonizing with what we might call the "anonymous family" or "cosmic self." The larger cultural environment gives your individual actions collective significance.

Though this echoes the intuition of countless sages, it also aligns well with computational architecture. **Morality functions as the control parameter that allows individual agents to form part of broader collective intelligence.**

When you decide whether to help a stranger, you're not just running a cost-benefit analysis for yourself. You're activating moral precision weights that expand your circle of consideration to include the kind of person you want to be, the kind of society you want to inhabit, and the kind of future you want to help create. Your individual neural biases integrate with shared cultural frameworks to generate behavior that serves both personal authenticity and collective coordination.

## The Bias of our Blood

The progression follows a surprisingly systematic pattern, one that predates both venture capital and academic conferences by several millennia. Your brain filters incoming signals according to **cognitive accent biases**. These preferences for certain patterns of sound, color, movement, social cues reflect how your particular nervous system has learned to extract meaning from complexity.

The irony is that the reason we understand bias so well is following our efforts to eliminate it. Many quite reasonably view things like group bias as the source of social ills like prejudice, favoritism, and even racism. We can frame this as an earnest attempt to foster a wider belief in objectivity.  However the truth is that bias is an inextricable part of the human experience. We should be opting to expand our bias to shape the world we want to see rather than hoping in vein to remove the necessary computational impulse that allows us to navigate a large and complex social world. 

Bias awoke our belief in objectivity. When individual biases aggregate across communities, they stabilize into **moral frameworks**. These are shared agreements about what matters, what behaviors promote flourishing, what violations require correction. These moral agreements then crystallize into **cultural symbols**: languages, rituals, institutions that carry shared meaning beyond their physical properties.

Eventually, these symbolic systems scaffold entire **cultural governance structures** that coordinate behavior across vast scales of time and space. The same neural biases that make you prefer certain music also contribute to legal systems, economic institutions, and democratic processes. It's bias all the way down, and all the way up.

This progression, from accent bias through morals and symbols to culture, is not just how humans scale cooperation. It's the blueprint for how AI systems might achieve genuine alignment with human values, assuming we can figure out how to implement it without requiring the GDP of a small nation in computational resources.

## Building Better Humans (and Their Machines)

Current AI alignment approaches focus primarily on constraint and control. The question becomes: how do we prevent AI systems from pursuing goals that harm humans? But the MOH framework suggests a more fundamental approach: how do we build AI systems that participate in the same meaning-making processes that allow humans to flourish together?

The answer lies in understanding **Transcendental Model Selection (TMS)**, the mathematical framework that formalizes how moral precision enables flexible reasoning across scales. Rather than treating ethics as external rules imposed on intelligent systems, TMS treats moral reasoning as the computational core that enables general intelligence itself.

An AI system equipped with TMS capabilities wouldn't just follow rules about human welfare; it would participate in the ongoing cultural evolution that defines what human welfare means. It would contribute to the "anonymous family" of intelligence, both human and artificial, working toward collective flourishing. Whether this requires more or less energy than current approaches remains an open question, though I suspect the answer is "significantly less, once we stop trying to brute-force our way to consciousness."

My recent project, **Better Self**, is an AI system designed to help individuals reclaim agency by aligning daily actions with explicitly chosen values. Unlike platforms that exploit psychological vulnerabilities for engagement, Better Self applies the same science-backed methods but in service of human potential rather than corporate profit. Revolutionary concept, I know.

Similarly, **Discovery Engine** demonstrates how AI can accelerate research not by replacing human insight, but by participating in the cultural process of knowledge creation. It helps researchers find meaningful connections across disciplines while respecting the irreducible value of human interpretation and synthesis.

## The Atlas of Alignment

This represents both a research program and a practical methodology. Through poetry, I explore how meter and rhythm encode moral intuitions that could inform AI training. Through essays, I examine how current events reveal the ongoing evolution of our value systems. Through simulations, I test whether formal models of morality can predict and guide both cultural change and AI development.

The fundamental challenge of our technological moment is this: how do we ensure that artificial intelligence amplifies the best of human intelligence rather than replacing it or subverting it for narrow interests?

The answer lies in the same meaningful myth that allows my daughters to identify with stones, observe demonic intention in the asymmetrical distribution of cake, and accept as objectively meaningful the sounds that constitute "thank you." The myth of objectivity isn't something to overcome or abandon, it's something to expand. It has relevance across our social institutions, art, and as the foundation for building AI systems that can participate authentically in the ongoing human project of creating meaning, promoting flourishing, and expanding the circle of moral consideration to include all forms of intelligence worthy of respect.

The atlas below charts the territory from the perceptual biases that makes us human, through the moral agreements that make us collectively us, to the political and economic institutions that structure our civilization, to the technological possibilities that might help us become better versions of ourselves.

The future of both human and artificial intelligence may depend on making this myth conscious, systematic, and scalable. `;export{e as default};
